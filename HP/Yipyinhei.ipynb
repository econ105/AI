{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/econ105/AI/blob/main/HP/Yipyinhei.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######THis is the HP MAP\n",
        "\n",
        "####### Reference is here : https://realpython.com/python-folium-web-maps-from-data/\n",
        "import folium\n",
        "from folium.features import DivIcon\n",
        "\n",
        "m = folium.Map(location=[20, 0], zoom_start=2, tiles=\"CartoDB Positron\")\n",
        "\n",
        "smart_airports = [\n",
        "    {\n",
        "        \"Rank\": 1,\n",
        "        \"Name\": \"Incheon Airport\",\n",
        "        \"Location\": \"South Korea\",\n",
        "        \"Smart Technologies\": \"IoT integration, automated immigration processes, digital wayfinding, health monitoring systems\",\n",
        "        \"Additional Details\": \"Implements a Smart Airport Plan including walkthrough self-service security screening, facial recognition-enabled SmartPass, home baggage drop-off, and AI robots for passenger assistance. Autonomous shuttle buses enhance intra-airport transportation.\",\n",
        "        \"lat\": 37.4691,\n",
        "        \"lon\": 126.4505\n",
        "    },\n",
        "    {\n",
        "        \"Rank\": 2,\n",
        "        \"Name\": \"Hong Kong International Airport\",\n",
        "        \"Location\": \"Hong Kong\",\n",
        "        \"Smart Technologies\": \"Automated check-in kiosks, smart baggage handling, AI-driven customer service\",\n",
        "        \"Additional Details\": \"Utilizes biometric solutions like Flight Token Travel for seamless check-in and boarding, smart security screening with CT-based X-ray technology, and IoT-augmented airfield service systems for efficient baggage handling.\",\n",
        "        \"lat\": 22.3080,\n",
        "        \"lon\": 113.9146\n",
        "    },\n",
        "    {\n",
        "        \"Rank\": 3,\n",
        "        \"Name\": \"Amsterdam Schiphol Airport\",\n",
        "        \"Location\": \"Netherlands\",\n",
        "        \"Smart Technologies\": \"Smart grid technology, intelligent lighting systems, automated baggage handling\",\n",
        "        \"Additional Details\": \"Examines time slot reservations for check-in and security to optimize passenger flow. Deploys IoT networks for real-time operational insights and uses collaborative robots (COBOTs) for automating baggage hall tasks.\",\n",
        "        \"lat\": 52.3086,\n",
        "        \"lon\": 4.7639\n",
        "    },\n",
        "    {\n",
        "        \"Rank\": 4,\n",
        "        \"Name\": \"Hamad International Airport\",\n",
        "        \"Location\": \"Qatar\",\n",
        "        \"Smart Technologies\": \"Biometric authentication, automated baggage handling, AI-driven customer service\",\n",
        "        \"Additional Details\": \"Features a fully automated baggage handling system with real-time tracking. AI-powered chatbots provide multilingual customer support, catering to diverse travelers.\",\n",
        "        \"lat\": 25.2731,\n",
        "        \"lon\": 51.6081\n",
        "    },\n",
        "    {\n",
        "        \"Rank\": 5,\n",
        "        \"Name\": \"Tokyo Haneda Airport\",\n",
        "        \"Location\": \"Japan\",\n",
        "        \"Smart Technologies\": \"Automated check-in kiosks, biometric authentication, AI-driven customer service\",\n",
        "        \"Additional Details\": \"Uses facial recognition for expedited security checks. AI-driven systems provide real-time flight information and personalized travel recommendations.\",\n",
        "        \"lat\": 35.5494,\n",
        "        \"lon\": 139.7798\n",
        "    },\n",
        "    {\n",
        "        \"Rank\": 6,\n",
        "        \"Name\": \"Munich Airport\",\n",
        "        \"Location\": \"Germany\",\n",
        "        \"Smart Technologies\": \"Smart parking management systems, real-time data sharing, automated baggage handling\",\n",
        "        \"Additional Details\": \"Employs AI for predictive maintenance of infrastructure and equipment. Intelligent parking systems optimize space utilization and reduce congestion.\",\n",
        "        \"lat\": 48.3538,\n",
        "        \"lon\": 11.7861\n",
        "    },\n",
        "    {\n",
        "        \"Rank\": 7,\n",
        "        \"Name\": \"San Francisco International Airport\",\n",
        "        \"Location\": \"USA\",\n",
        "        \"Smart Technologies\": \"Automated check-in kiosks, smart baggage handling, AI-driven customer service\",\n",
        "        \"Additional Details\": \"Deploys AI chatbots and virtual assistants for real-time flight updates and personalized recommendations. Smart baggage handling systems reduce lost luggage incidents.\",\n",
        "        \"lat\": 37.6152,\n",
        "        \"lon\": -122.3910\n",
        "    }\n",
        "]\n",
        "\n",
        "sustainable_airports = [\n",
        "    {\n",
        "        \"Rank\": 1,\n",
        "        \"Name\": \"Denver International Airport\",\n",
        "        \"Location\": \"United States\",\n",
        "        \"Sustainable Elements\": \"Largest solar power farm, energy-efficient technologies\",\n",
        "        \"Additional Details\": \"Hosts one of the world's largest solar arrays, spanning over 150 acres, generating significant renewable energy. Implements a state-of-the-art deicing fluid recycling system capturing 70% of applied fluid.\",\n",
        "        \"lat\": 39.8561,\n",
        "        \"lon\": -104.6737\n",
        "    },\n",
        "    {\n",
        "        \"Rank\": 2,\n",
        "        \"Name\": \"Stockholm Arlanda Airport\",\n",
        "        \"Location\": \"Sweden\",\n",
        "        \"Sustainable Elements\": \"Energy-efficient lighting, waste reduction programs\",\n",
        "        \"Additional Details\": \"Utilizes intelligent lighting systems that adjust based on occupancy and natural light, reducing energy consumption. Robust recycling programs divert significant waste from landfills.\",\n",
        "        \"lat\": 59.6519,\n",
        "        \"lon\": 17.9186\n",
        "    },\n",
        "    {\n",
        "        \"Rank\": 3,\n",
        "        \"Name\": \"Indira Gandhi International Airport\",\n",
        "        \"Location\": \"India\",\n",
        "        \"Sustainable Elements\": \"Green building practices, renewable energy sources\",\n",
        "        \"Additional Details\": \"Adopts green building certifications (e.g., LEED) for terminal construction. Uses renewable energy sources like solar power for terminal operations and implements water conservation measures.\",\n",
        "        \"lat\": 28.5665,\n",
        "        \"lon\": 77.1031\n",
        "    },\n",
        "    {\n",
        "        \"Rank\": 4,\n",
        "        \"Name\": \"Galapagos Ecological Airport\",\n",
        "        \"Location\": \"Galapagos Islands\",\n",
        "        \"Sustainable Elements\": \"Solar panels, wind power, modular design\",\n",
        "        \"Additional Details\": \"Operates entirely on solar and wind power, achieving carbon neutrality. Modular design minimizes environmental impact during construction.\",\n",
        "        \"lat\": -0.4538,\n",
        "        \"lon\": -90.2659\n",
        "    },\n",
        "    {\n",
        "        \"Rank\": 5,\n",
        "        \"Name\": \"Oslo Airport\",\n",
        "        \"Location\": \"Norway\",\n",
        "        \"Sustainable Elements\": \"Renewable energy adoption, sustainable practices\",\n",
        "        \"Additional Details\": \"Relies heavily on renewable energy sources like hydropower. Implements AI-optimized HVAC systems to minimize energy consumption.\",\n",
        "        \"lat\": 60.1939,\n",
        "        \"lon\": 11.1004\n",
        "    },\n",
        "    {\n",
        "        \"Rank\": 6,\n",
        "        \"Name\": \"Boston Logan International Airport\",\n",
        "        \"Location\": \"USA\",\n",
        "        \"Sustainable Elements\": \"Energy-efficient lighting, waste reduction programs\",\n",
        "        \"Additional Details\": \"Implements rainwater harvesting systems and low-flow fixtures to reduce water usage. Focuses on waste diversion through comprehensive recycling programs.\",\n",
        "        \"lat\": 42.3643,\n",
        "        \"lon\": -71.0052\n",
        "    },\n",
        "    {\n",
        "        \"Rank\": 7,\n",
        "        \"Name\": \"San Diego International Airport\",\n",
        "        \"Location\": \"USA\",\n",
        "        \"Sustainable Elements\": \"Energy-efficient technologies, waste reduction programs\",\n",
        "        \"Additional Details\": \"Uses energy-efficient lighting and HVAC systems. Implements waste reduction programs targeting zero waste to landfill.\",\n",
        "        \"lat\": 32.7336,\n",
        "        \"lon\": -117.1897\n",
        "    }\n",
        "]\n",
        "\n",
        "hybrid_airports = [\n",
        "    {\n",
        "        \"Rank\": 1,\n",
        "        \"Name\": \"Singapore Changi Airport\",\n",
        "        \"Location\": \"Singapore\",\n",
        "        \"Smart Technologies\": \"Biometric authentication, automated baggage handling, AI-driven customer service solutions, real-time data sharing, Blockchain technologies\",\n",
        "        \"Sustainable Elements\": \"Solar panels, energy-efficient lighting, water conservation measures, recycling programs\",\n",
        "        \"Additional Details\": \"Features the Jewel Changi with sustainable design elements like rainwater harvesting and green spaces. Achieves high sustainability ratings through comprehensive waste management.\",\n",
        "        \"lat\": 1.3644,\n",
        "        \"lon\": 103.9915\n",
        "    },\n",
        "    {\n",
        "        \"Rank\": 2,\n",
        "        \"Name\": \"Dubai International Airport\",\n",
        "        \"Location\": \"UAE\",\n",
        "        \"Smart Technologies\": \"AI-driven customer service, automated processes, real-time data sharing, ‘Smart Corridor’ project, IoT\",\n",
        "        \"Sustainable Elements\": \"Flow arrestors, electric cars, robust recycling program\",\n",
        "        \"Additional Details\": \"Implements a comprehensive waste diversion program aiming for zero waste to landfill. Uses electric vehicles for ground transportation.\",\n",
        "        \"lat\": 25.2528,\n",
        "        \"lon\": 55.3644\n",
        "    },\n",
        "    {\n",
        "        \"Rank\": 3,\n",
        "        \"Name\": \"Zurich Airport\",\n",
        "        \"Location\": \"Switzerland\",\n",
        "        \"Smart Technologies\": \"Digital services, mobile apps for flight tracking, automated baggage handling\",\n",
        "        \"Sustainable Elements\": \"Energy-efficient technologies, waste reduction programs, waste water from de-icing\",\n",
        "        \"Additional Details\": \"Utilizes geothermal energy for heating and cooling. Implements waste reduction programs alongside digital services for operational efficiency.\",\n",
        "        \"lat\": 47.4647,\n",
        "        \"lon\": 8.5492\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "def create_popup_content(airport, category):\n",
        "    html = f\"\"\"\n",
        "    <div style=\"font-family: Arial; font-size: 12px; width: 300px; line-height: 1.5;\">\n",
        "        <h4 style=\"margin-bottom: 10px;\">{airport['Name']} ({category})</h4>\n",
        "        <div style=\"margin-bottom: 8px;\"><b>Rank:</b> {airport['Rank']}</div>\n",
        "        <div style=\"margin-bottom: 8px;\"><b>Location:</b> {airport['Location']}</div>\n",
        "    \"\"\"\n",
        "    if category in [\"Smart\", \"Hybrid\"]:\n",
        "        html += f'<div style=\"margin-bottom: 8px;\"><b>Smart Technologies:</b> {airport[\"Smart Technologies\"]}</div>'\n",
        "    if category in [\"Sustainable\", \"Hybrid\"]:\n",
        "        html += f'<div style=\"margin-bottom: 8px;\"><b>Sustainable Elements:</b> {airport[\"Sustainable Elements\"]}</div>'\n",
        "    html += f\"\"\"\n",
        "        <div style=\"margin-bottom: 8px;\"><b>Additional Details:</b> {airport['Additional Details']}</div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    return html\n",
        "\n",
        "for airport in smart_airports:\n",
        "    popup_content = create_popup_content(airport, \"Smart\")\n",
        "    folium.Marker(\n",
        "        location=[airport[\"lat\"], airport[\"lon\"]],\n",
        "        popup=folium.Popup(popup_content, max_width=350),\n",
        "        icon=folium.Icon(color=\"blue\", icon=\"plane\"),\n",
        "    ).add_to(m)\n",
        "\n",
        "for airport in sustainable_airports:\n",
        "    popup_content = create_popup_content(airport, \"Sustainable\")\n",
        "    folium.Marker(\n",
        "        location=[airport[\"lat\"], airport[\"lon\"]],\n",
        "        popup=folium.Popup(popup_content, max_width=350),\n",
        "        icon=folium.Icon(color=\"green\", icon=\"plane\"),\n",
        "    ).add_to(m)\n",
        "\n",
        "for airport in hybrid_airports:\n",
        "    popup_content = create_popup_content(airport, \"Hybrid\")\n",
        "    folium.Marker(\n",
        "        location=[airport[\"lat\"], airport[\"lon\"]],\n",
        "        popup=folium.Popup(popup_content, max_width=350),\n",
        "        icon=folium.Icon(color=\"purple\", icon=\"plane\"),\n",
        "    ).add_to(m)\n",
        "\n",
        "legend_html = \"\"\"\n",
        "<div style=\"position: fixed; bottom: 50px; left: 50px; z-index:9999; font-size:14px;\n",
        "            background-color:white; padding:10px; border:2px solid grey;\">\n",
        "    <p><strong>Airport Categories</strong></p>\n",
        "    <p><i class=\"fa fa-circle\" style=\"color:blue\"></i> Smart Airports</p>\n",
        "    <p><i class=\"fa fa-circle\" style=\"color:green\"></i> Sustainable Airports</p>\n",
        "    <p><i class=\"fa fa-circle\" style=\"color:purple\"></i> Hybrid Airports</p>\n",
        "</div>\n",
        "\"\"\"\n",
        "m.get_root().html.add_child(folium.Element(legend_html))\n",
        "\n",
        "m.save(\"BevanHP_airports_map.html\")"
      ],
      "metadata": {
        "id": "0OgotdKINoQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######1 sentiment 1= positive , 0 = negative\n",
        "#### this is the sentiment analysis\n",
        "!pip install transformers pandas openpyxl tqdm\n",
        "\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "from google.colab import files\n",
        "import io\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "tqdm.pandas()\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def load_sentiment_classifier():\n",
        "    \"\"\"Initialize the sentiment classifier pipeline.\"\"\"\n",
        "    try:\n",
        "        logger.info(\"Loading sentiment classifier model...\")\n",
        "        classifier = pipeline(\n",
        "            \"text-classification\",\n",
        "            model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "            return_all_scores=True,\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "        logger.info(\"Sentiment model loaded successfully.\")\n",
        "        return classifier\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading sentiment model: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def get_sentiment(text, classifier):\n",
        "    \"\"\"Determine the sentiment and score for a given text based on three score ranges.\"\"\"\n",
        "    try:\n",
        "        if pd.isna(text) or not isinstance(text, str) or text.strip() == \"\":\n",
        "            return \"neutral\", 0.0\n",
        "        results = classifier(text)[0]\n",
        "\n",
        "        positive_score = next(r['score'] for r in results if r['label'] == 'POSITIVE')\n",
        "\n",
        "        if positive_score >= 0.7:\n",
        "            return \"positive\", positive_score\n",
        "        elif positive_score > 0.3:\n",
        "            return \"neutral\", positive_score\n",
        "        else:\n",
        "            return \"negative\", positive_score\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Error processing text for sentiment: {text[:50] if isinstance(text, str) else text}... Error: {str(e)}\")\n",
        "        return \"neutral\", 0.0  \\\n",
        "\n",
        "def process_file(file_name, file_content, sentiment_classifier, airport_mapping):\n",
        "    \"\"\"Process an Excel file and analyze sentiments in Column A.\"\"\"\n",
        "    try:\n",
        "        logger.info(f\"Processing {file_name}...\")\n",
        "        print(f\"\\nProcessing {file_name}...\")\n",
        "\n",
        "        df = pd.read_excel(io.BytesIO(file_content))\n",
        "\n",
        "        if df.empty:\n",
        "            logger.error(f\"{file_name} is empty.\")\n",
        "            print(f\"Error: {file_name} is empty. Skipping...\")\n",
        "            return None\n",
        "\n",
        "        if df.columns.empty:\n",
        "            logger.error(f\"No columns found in {file_name}\")\n",
        "            print(f\"Error: No columns found in {file_name}. Skipping...\")\n",
        "            return None\n",
        "        text_column = df.columns[0]\n",
        "        logger.info(f\"Using first column: {text_column}\")\n",
        "\n",
        "        print(f\"Analyzing sentiments for {len(df)} comments in {file_name}...\")\n",
        "        valid_texts = df[text_column].notna() & df[text_column].apply(lambda x: isinstance(x, str) and x.strip() != \"\")\n",
        "        num_valid = valid_texts.sum()\n",
        "        num_invalid = len(df) - num_valid\n",
        "        logger.info(f\"Found {num_valid} valid texts and {num_invalid} invalid/empty texts in {file_name}\")\n",
        "        sentiments = df[text_column].progress_apply(lambda x: get_sentiment(x, sentiment_classifier))\n",
        "        df['sentiment'], df['sentiment_score'] = zip(*sentiments)\n",
        "\n",
        "        sentiment_counts = df['sentiment'].value_counts()\n",
        "        total_comments = num_valid\n",
        "        positive = (sentiment_counts.get('positive', 0) / total_comments * 100) if total_comments > 0 else 0\n",
        "        negative = (sentiment_counts.get('negative', 0) / total_comments * 100) if total_comments > 0 else 0\n",
        "        neutral = (sentiment_counts.get('neutral', 0) / total_comments * 100) if total_comments > 0 else 0\n",
        "\n",
        "        airport_name = airport_mapping.get(file_name, \"Unknown Airport\")\n",
        "        logger.info(f\"Airport identified: {airport_name} from file {file_name}\")\n",
        "\n",
        "        print(f\"\\nSentiment Distribution in {file_name} for {airport_name}:\")\n",
        "        print(f\"  Positive: {positive:.2f}%\")\n",
        "        print(f\"  Negative: {negative:.2f}%\")\n",
        "        print(f\"  Neutral: {neutral:.2f}%\")\n",
        "        print(f\"  Total Valid Comments: {total_comments}\")\n",
        "        print(f\"  Invalid/empty texts skipped: {num_invalid}\")\n",
        "\n",
        "        output_file = f\"updated_{file_name}\"\n",
        "        df.to_excel(output_file, index=False)\n",
        "        logger.info(f\"Saved updated file: {output_file}\")\n",
        "        print(f\"Saved updated file: {output_file}\")\n",
        "        files.download(output_file)\n",
        "        logger.info(f\"Downloaded {output_file}\")\n",
        "\n",
        "        return {\n",
        "            \"airport\": airport_name,\n",
        "            \"positive\": round(positive, 2),\n",
        "            \"negative\": round(negative, 2),\n",
        "            \"neutral\": round(neutral, 2),\n",
        "            \"total_comments\": total_comments\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error processing {file_name}: {str(e)}\")\n",
        "        print(f\"Error processing {file_name}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to process multiple Excel files in Colab.\"\"\"\n",
        "    try:\n",
        "        airport_mapping = {\n",
        "            \"Incheon_Airport_comments.xlsx\": \"Incheon Airport\",\n",
        "            \"Hong_Kong_International_comments.xlsx\": \"Hong Kong International\",\n",
        "            \"Amsterdam_Schiphol_comments.xlsx\": \"Amsterdam Schiphol\",\n",
        "            \"Hamad_International_comments.xlsx\": \"Hamad International\",\n",
        "            \"Tokyo_Haneda_comments.xlsx\": \"Tokyo Haneda\",\n",
        "            \"Munich_Airport_comments.xlsx\": \"Munich Airport\",\n",
        "            \"San_Francisco_International_comments.xlsx\": \"San Francisco International\",\n",
        "            \"Denver_International_comments.xlsx\": \"Denver International\",\n",
        "            \"Stockholm_Arlanda_comments.xlsx\": \"Stockholm Arlanda\",\n",
        "            \"Indira_Gandhi_International_comments.xlsx\": \"Indira Gandhi International\",\n",
        "            \"Galapagos_Ecological_comments.xlsx\": \"Galapagos Ecological\",\n",
        "            \"Oslo_Airport_comments.xlsx\": \"Oslo Airport\",\n",
        "            \"Boston_Logan_comments.xlsx\": \"Boston Logan\",\n",
        "            \"San_Diego_International_comments.xlsx\": \"San Diego International\",\n",
        "            \"Singapore_Changi_comments.xlsx\": \"Singapore Changi\",\n",
        "            \"Dubai_International_comments.xlsx\": \"Dubai International\",\n",
        "            \"Zurich_Airport_comments.xlsx\": \"Zurich Airport\"\n",
        "        }\n",
        "\n",
        "        table_data = [\n",
        "            {\"Category\": \"Smart\", \"Rank\": 1, \"Airport Name\": \"Incheon Airport\"},\n",
        "            {\"Category\": \"Smart\", \"Rank\": 2, \"Airport Name\": \"Hong Kong International\"},\n",
        "            {\"Category\": \"Smart\", \"Rank\": 3, \"Airport Name\": \"Amsterdam Schiphol\"},\n",
        "            {\"Category\": \"Smart\", \"Rank\": 4, \"Airport Name\": \"Hamad International\"},\n",
        "            {\"Category\": \"Smart\", \"Rank\": 5, \"Airport Name\": \"Tokyo Haneda\"},\n",
        "            {\"Category\": \"Smart\", \"Rank\": 6, \"Airport Name\": \"Munich Airport\"},\n",
        "            {\"Category\": \"Smart\", \"Rank\": 7, \"Airport Name\": \"San Francisco International\"},\n",
        "            {\"Category\": \"Sustainable\", \"Rank\": 1, \"Airport Name\": \"Denver International\"},\n",
        "            {\"Category\": \"Sustainable\", \"Rank\": 2, \"Airport Name\": \"Stockholm Arlanda\"},\n",
        "            {\"Category\": \"Sustainable\", \"Rank\": 3, \"Airport Name\": \"Indira Gandhi International\"},\n",
        "            {\"Category\": \"Sustainable\", \"Rank\": 4, \"Airport Name\": \"Galapagos Ecological\"},\n",
        "            {\"Category\": \"Sustainable\", \"Rank\": 5, \"Airport Name\": \"Oslo Airport\"},\n",
        "            {\"Category\": \"Sustainable\", \"Rank\": 6, \"Airport Name\": \"Boston Logan\"},\n",
        "            {\"Category\": \"Sustainable\", \"Rank\": 7, \"Airport Name\": \"San Diego International\"},\n",
        "            {\"Category\": \"Hybrid\", \"Rank\": 1, \"Airport Name\": \"Singapore Changi\"},\n",
        "            {\"Category\": \"Hybrid\", \"Rank\": 2, \"Airport Name\": \"Dubai International\"},\n",
        "            {\"Category\": \"Hybrid\", \"Rank\": 3, \"Airport Name\": \"Zurich Airport\"}\n",
        "        ]\n",
        "\n",
        "        print(\"Please upload your 17 Excel files:\")\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        input_files = list(uploaded.keys())\n",
        "        if len(input_files) != 17:\n",
        "            logger.error(f\"Expected 17 files, but {len(input_files)} were uploaded.\")\n",
        "            print(f\"Error: Expected 17 files, but {len(input_files)} were uploaded.\")\n",
        "            return\n",
        "\n",
        "        sentiment_classifier = load_sentiment_classifier()\n",
        "\n",
        "        results = []\n",
        "        for file_name in input_files:\n",
        "            result = process_file(file_name, uploaded[file_name], sentiment_classifier, airport_mapping)\n",
        "            if result:\n",
        "                results.append(result)\n",
        "\n",
        "        for entry in table_data:\n",
        "            airport_name = entry[\"Airport Name\"]\n",
        "            matching_result = next((r for r in results if r[\"airport\"] == airport_name), None)\n",
        "            if matching_result:\n",
        "                entry[\"Positive (%)\"] = matching_result[\"positive\"]\n",
        "                entry[\"Negative (%)\"] = matching_result[\"negative\"]\n",
        "                entry[\"Neutral (%)\"] = matching_result[\"neutral\"]\n",
        "                entry[\"Total Comments\"] = matching_result[\"total_comments\"]\n",
        "            else:\n",
        "                logger.warning(f\"No sentiment data found for {airport_name}\")\n",
        "                print(f\"Warning: No sentiment data found for {airport_name}\")\n",
        "                entry[\"Positive (%)\"] = 0\n",
        "                entry[\"Negative (%)\"] = 0\n",
        "                entry[\"Neutral (%)\"] = 0\n",
        "                entry[\"Total Comments\"] = 0\n",
        "\n",
        "        print(\"\\n=== Updated Sentiment Distribution Table ===\")\n",
        "        print(\"| Category    | Rank | Airport Name               | Positive (%) | Negative (%) | Neutral (%) | Total Comments |\")\n",
        "        print(\"|-------------|------|----------------------------|--------------|--------------|-------------|----------------|\")\n",
        "        for entry in table_data:\n",
        "            print(f\"| {entry['Category']:<11} | {entry['Rank']:<4} | {entry['Airport Name']:<26} | {entry['Positive (%)']:<12} | {entry['Negative (%)']:<12} | {entry['Neutral (%)']:<11} | {entry['Total Comments']:<14} |\")\n",
        "\n",
        "        print(\"\\n=== Processing Summary ===\")\n",
        "        print(f\"Total files processed: {len(results)}\")\n",
        "        print(\"Processing complete. Updated table is displayed above.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in main execution: {str(e)}\")\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "lW6zA_p1sxAy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "e0ba7581-8910-4da1-a088-45f3adc8f8b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Please upload your 17 Excel files:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c5dcffff-9b2e-46b3-be8d-32cf8a9ba7ea\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c5dcffff-9b2e-46b3-be8d-32cf8a9ba7ea\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######this is emotional analysis\n",
        "!pip install transformers pandas openpyxl tqdm\n",
        "\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "from google.colab import files\n",
        "import io\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def load_emotion_classifier():\n",
        "    \"\"\"Initialize the emotion classifier pipeline.\"\"\"\n",
        "    try:\n",
        "        logger.info(\"Loading emotion classifier model...\")\n",
        "        classifier = pipeline(\n",
        "            \"text-classification\",\n",
        "            model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
        "            return_all_scores=True,\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "        logger.info(\"Emotion model loaded successfully.\")\n",
        "        return classifier\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading emotion model: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def get_emotion(text, classifier):\n",
        "    \"\"\"Determine the dominant emotion for a given text.\"\"\"\n",
        "    try:\n",
        "        if pd.isna(text) or not isinstance(text, str) or text.strip() == \"\":\n",
        "            return \"neutral\"\n",
        "        results = classifier(text)[0]\n",
        "        return max(results, key=lambda x: x['score'])['label']\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Error processing text for emotion: {text[:50] if isinstance(text, str) else text}... Error: {str(e)}\")\n",
        "        return \"neutral\"\n",
        "\n",
        "def process_file(file_name, file_content, emotion_classifier):\n",
        "    \"\"\"Process an Excel file and analyze emotions in Column A.\"\"\"\n",
        "    try:\n",
        "        logger.info(f\"Processing {file_name}...\")\n",
        "        print(f\"\\nProcessing {file_name}...\")\n",
        "\n",
        "\n",
        "        df = pd.read_excel(io.BytesIO(file_content))\n",
        "\n",
        "\n",
        "        if df.empty:\n",
        "            logger.error(f\"{file_name} is empty.\")\n",
        "            print(f\"Error: {file_name} is empty. Skipping...\")\n",
        "            return False\n",
        "\n",
        "\n",
        "        if df.columns.empty:\n",
        "            logger.error(f\"No columns found in {file_name}\")\n",
        "            print(f\"Error: No columns found in {file_name}. Skipping...\")\n",
        "            return False\n",
        "        text_column = df.columns[0]\n",
        "        logger.info(f\"Using first column: {text_column}\")\n",
        "\n",
        "\n",
        "        print(f\"Analyzing emotions for {len(df)} comments in {file_name}...\")\n",
        "        valid_texts = df[text_column].notna() & df[text_column].apply(lambda x: isinstance(x, str) and x.strip() != \"\")\n",
        "        num_valid = valid_texts.sum()\n",
        "        num_invalid = len(df) - num_valid\n",
        "        logger.info(f\"Found {num_valid} valid texts and {num_invalid} invalid/empty texts in {file_name}\")\n",
        "        df['emotion'] = df[text_column].progress_apply(lambda x: get_emotion(x, emotion_classifier))\n",
        "\n",
        "        emotion_counts = df['emotion'].value_counts()\n",
        "        print(f\"\\nEmotion Distribution in {file_name}:\")\n",
        "        for emotion, count in emotion_counts.items():\n",
        "            print(f\"  {emotion}: {count}\")\n",
        "        print(f\"Valid texts processed: {num_valid}\")\n",
        "        print(f\"Invalid/empty texts skipped: {num_invalid}\")\n",
        "\n",
        "\n",
        "        output_file = f\"updated_{file_name}\"\n",
        "        df.to_excel(output_file, index=False)\n",
        "        logger.info(f\"Saved updated file: {output_file}\")\n",
        "        print(f\"Saved updated file: {output_file}\")\n",
        "\n",
        "        files.download(output_file)\n",
        "        logger.info(f\"Downloaded {output_file}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error processing {file_name}: {str(e)}\")\n",
        "        print(f\"Error processing {file_name}: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to process an Excel file in Colab.\"\"\"\n",
        "    try:\n",
        "        print(\"Please upload your Excel file:\")\n",
        "        uploaded = files.upload()\n",
        "\n",
        "\n",
        "        input_files = list(uploaded.keys())\n",
        "        if not input_files:\n",
        "            logger.error(\"No file uploaded.\")\n",
        "            print(\"Error: No file uploaded.\")\n",
        "            return\n",
        "        if len(input_files) > 1:\n",
        "            logger.warning(\"Multiple files uploaded. Processing only the first file.\")\n",
        "            print(\"Warning: Multiple files uploaded. Processing only the first file.\")\n",
        "\n",
        "\n",
        "        emotion_classifier = load_emotion_classifier()\n",
        "\n",
        "\n",
        "        file_name = input_files[0]\n",
        "        success = process_file(file_name, uploaded[file_name], emotion_classifier)\n",
        "\n",
        "\n",
        "        print(\"\\n=== Processing Summary ===\")\n",
        "        print(f\"File processed: {file_name}\")\n",
        "        print(f\"Status: {'Success' if success else 'Failed'}\")\n",
        "        logger.info(f\"Processed {file_name}: {'Success' if success else 'Failed'}\")\n",
        "        print(\"\\nProcessing complete. Check downloaded file for results.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in main execution: {str(e)}\")\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "2bDhhr-xkyW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######this is orginal emotion and sentiment analysis combine together\n",
        "####### THIS CODE IS sentiment and analysis and emotion analysis\n",
        "####### this sentiment analysis output (the score set to 0.65 to returen netural), this is not updated\n",
        "\n",
        "\n",
        "!pip install transformers pandas openpyxl tqdm\n",
        "\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "from google.colab import files\n",
        "import io\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Enable tqdm for pandas\n",
        "tqdm.pandas()\n",
        "\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def load_emotion_classifier():\n",
        "    \"\"\"Initialize the emotion classifier pipeline.\"\"\"\n",
        "    try:\n",
        "        logger.info(\"Loading emotion classifier model...\")\n",
        "        classifier = pipeline(\n",
        "            \"text-classification\",\n",
        "            model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
        "            return_all_scores=True,\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "        logger.info(\"Emotion model loaded successfully.\")\n",
        "        return classifier\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading emotion model: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def load_sentiment_classifier():\n",
        "    \"\"\"Initialize the sentiment classifier pipeline.\"\"\"\n",
        "    try:\n",
        "        logger.info(\"Loading sentiment classifier model...\")\n",
        "        classifier = pipeline(\n",
        "            \"text-classification\",\n",
        "            model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "            return_all_scores=True,\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "        logger.info(\"Sentiment model loaded successfully.\")\n",
        "        return classifier\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading sentiment model: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def get_emotion(text, classifier):\n",
        "    \"\"\"Determine the dominant emotion for a given text.\"\"\"\n",
        "    try:\n",
        "        if pd.isna(text) or not isinstance(text, str) or text.strip() == \"\":\n",
        "            return \"neutral\"\n",
        "        results = classifier(text)[0]\n",
        "        return max(results, key=lambda x: x['score'])['label']\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Error processing text for emotion: {text[:50] if isinstance(text, str) else text}... Error: {str(e)}\")\n",
        "        return \"neutral\"\n",
        "\n",
        "def get_sentiment(text, classifier):\n",
        "    \"\"\"Determine the sentiment and score for a given text.\"\"\"\n",
        "    try:\n",
        "        if pd.isna(text) or not isinstance(text, str) or text.strip() == \"\":\n",
        "            return \"neutral\", 0.0\n",
        "        results = classifier(text)[0]\n",
        "        top_result = max(results, key=lambda x: x['score'])\n",
        "        label = top_result['label'].lower()\n",
        "        score = top_result['score']\n",
        "        if score < 0.65:\n",
        "            return \"neutral\", score\n",
        "        return label, score\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Error processing text for sentiment: {text[:50] if isinstance(text, str) else text}... Error: {str(e)}\")\n",
        "        return \"neutral\", 0.0\n",
        "\n",
        "def process_file(file_name, file_content, emotion_classifier, sentiment_classifier):\n",
        "    \"\"\"Process an Excel file and analyze emotions and sentiments in Column A.\"\"\"\n",
        "    try:\n",
        "        logger.info(f\"Processing {file_name}...\")\n",
        "        print(f\"\\nProcessing {file_name}...\")\n",
        "\n",
        "\n",
        "        df = pd.read_excel(io.BytesIO(file_content))\n",
        "\n",
        "\n",
        "        if df.empty:\n",
        "            logger.error(f\"{file_name} is empty.\")\n",
        "            print(f\"Error: {file_name} is empty. Skipping...\")\n",
        "            return False\n",
        "\n",
        "#  first column (Column A) is the comments\n",
        "        if df.columns.empty:\n",
        "            logger.error(f\"No columns found in {file_name}\")\n",
        "            print(f\"Error: No columns found in {file_name}. Skipping...\")\n",
        "            return False\n",
        "        text_column = df.columns[0]\n",
        "        logger.info(f\"Using first column: {text_column}\")\n",
        "\n",
        "###### progress bar\n",
        "        print(f\"Analyzing emotions for {len(df)} comments in {file_name}...\")\n",
        "        valid_texts = df[text_column].notna() & df[text_column].apply(lambda x: isinstance(x, str) and x.strip() != \"\")\n",
        "        num_valid = valid_texts.sum()\n",
        "        num_invalid = len(df) - num_valid\n",
        "        logger.info(f\"Found {num_valid} valid texts and {num_invalid} invalid/empty texts in {file_name}\")\n",
        "        df['emotion'] = df[text_column].progress_apply(lambda x: get_emotion(x, emotion_classifier))\n",
        "\n",
        "        print(f\"Analyzing sentiments for {len(df)} comments in {file_name}...\")\n",
        "        sentiments = df[text_column].progress_apply(lambda x: get_sentiment(x, sentiment_classifier))\n",
        "        df['sentiment'], df['sentiment_score'] = zip(*sentiments)\n",
        "\n",
        "        emotion_counts = df['emotion'].value_counts()\n",
        "        sentiment_counts = df['sentiment'].value_counts()\n",
        "        print(f\"\\nEmotion Distribution in {file_name}:\")\n",
        "        for emotion, count in emotion_counts.items():\n",
        "            print(f\"  {emotion}: {count}\")\n",
        "        print(f\"\\nSentiment Distribution in {file_name}:\")\n",
        "        for sentiment, count in sentiment_counts.items():\n",
        "            print(f\"  {sentiment}: {count}\")\n",
        "        print(f\"Valid texts processed: {num_valid}\")\n",
        "        print(f\"Invalid/empty texts skipped: {num_invalid}\")\n",
        "\n",
        "        output_file = f\"updated_{file_name}\"\n",
        "        df.to_excel(output_file, index=False)\n",
        "        logger.info(f\"Saved updated file: {output_file}\")\n",
        "        print(f\"Saved updated file: {output_file}\")\n",
        "\n",
        "        files.download(output_file)\n",
        "        logger.info(f\"Downloaded {output_file}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error processing {file_name}: {str(e)}\")\n",
        "        print(f\"Error processing {file_name}: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to process an Excel file in Colab.\"\"\"\n",
        "    try:\n",
        "\n",
        "        print(\"Please upload your Excel file:\")\n",
        "        uploaded = files.upload()\n",
        "\n",
        "# Checking the file is it uploaded or not\n",
        "        input_files = list(uploaded.keys())\n",
        "        if not input_files:\n",
        "            logger.error(\"No file uploaded.\")\n",
        "            print(\"Error: No file uploaded.\")\n",
        "            return\n",
        "        if len(input_files) > 1:\n",
        "            logger.warning(\"Multiple files uploaded. Processing only the first file.\")\n",
        "            print(\"Warning: Multiple files uploaded. Processing only the first file.\")\n",
        "\n",
        "# classifer display\n",
        "        emotion_classifier = load_emotion_classifier()\n",
        "        sentiment_classifier = load_sentiment_classifier()\n",
        "\n",
        "# Process the first file in here\n",
        "        file_name = input_files[0]\n",
        "        success = process_file(file_name, uploaded[file_name], emotion_classifier, sentiment_classifier)\n",
        "\n",
        "# Summary display here\n",
        "        print(\"\\n=== Processing Summary ===\")\n",
        "        print(f\"File processed: {file_name}\")\n",
        "        print(f\"Status: {'Success' if success else 'Failed'}\")\n",
        "        logger.info(f\"Processed {file_name}: {'Success' if success else 'Failed'}\")\n",
        "        print(\"\\nProcessing complete. Check downloaded file for results.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in main execution: {str(e)}\")\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "KEARo7Y5tVmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######CLUSTERING\n",
        "####for presentation\n",
        "###this is the clustering and wordcloud\n",
        "\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "from IPython.display import display, HTML\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold import TSNE\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "custom_stop_words = {\n",
        "    'amsterdam': ['amsterdam', 'schiphol', 'even', 'however'],\n",
        "    'boston': ['boston', 'logan', 'also'],\n",
        "    'denver': ['denver', 'international'],\n",
        "    'dubai': ['dubai', 'international', 'even'],\n",
        "    'galapagos': ['galapagos', 'ecological', 'is', 'must', 'either'],\n",
        "    'hamad': ['hamad', 'international', 'would', 'even', 'around'],\n",
        "    'hongkong': ['hong', 'kong', 'hk', 'international', 'also', 'would', 'around'],\n",
        "    'incheon': ['incheon', 'also', 'would', 'even', 'maybe', 'really'],\n",
        "    'indiragandhi': ['indira', 'gandhi', 'international', 'u', 'hi', 'would', 'could'],\n",
        "    'munich': ['munich', 'always', 'never', 'said', 'probably'],\n",
        "    'oslo': ['oslo', 'plenty', 'even', 'via'],\n",
        "    'sanfrancisco': ['san', 'francisco', 'international', 'also', 'even', 'would'],\n",
        "    'sandiego': ['san', 'diego', 'international', 'is', 'was', 'maybe'],\n",
        "    'singapore': ['singapore', 'changi', 'also', 'around', 'really'],\n",
        "    'stockholm': ['stockholm', 'arlanda', 'even', 'probably', 'via'],\n",
        "    'tokyo': ['tokyo', 'haneda', 'would', 'even', 'always'],\n",
        "    'zurich': ['zurich', 'is', 'are', 'however']\n",
        "}\n",
        "\n",
        "for words in custom_stop_words.values():\n",
        "    stop_words.update(words)\n",
        "\n",
        "stop_words.add('airport')\n",
        "\n",
        "airport_categories = {\n",
        "    'Smart': [\n",
        "        'Incheon Airport', 'Hong Kong International', 'Amsterdam Schiphol',\n",
        "        'Hamad International', 'Tokyo Haneda', 'Munich Airport',\n",
        "        'San Francisco International'\n",
        "    ],\n",
        "    'Sustainable': [\n",
        "        'Denver International', 'Stockholm Arlanda', 'Indira Gandhi International',\n",
        "        'Galapagos Ecological', 'Oslo Airport', 'Boston Logan',\n",
        "        'San Diego International'\n",
        "    ],\n",
        "    'Hybrid': [\n",
        "        'Singapore Changi', 'Dubai International', 'Zurich Airport'\n",
        "    ]\n",
        "}\n",
        "\n",
        "filename_to_airport = {\n",
        "    'incheon': 'Incheon Airport',\n",
        "    'hongkong': 'Hong Kong International',\n",
        "    'amsterdam': 'Amsterdam Schiphol',\n",
        "    'hamad': 'Hamad International',\n",
        "    'tokyo': 'Tokyo Haneda',\n",
        "    'munich': 'Munich Airport',\n",
        "    'sanfrancisco': 'San Francisco International',\n",
        "    'denver': 'Denver International',\n",
        "    'stockholm': 'Stockholm Arlanda',\n",
        "    'indiragandhi': 'Indira Gandhi International',\n",
        "    'galapagos': 'Galapagos Ecological',\n",
        "    'oslo': 'Oslo Airport',\n",
        "    'boston': 'Boston Logan',\n",
        "    'sandiego': 'San Diego International',\n",
        "    'singapore': 'Singapore Changi',\n",
        "    'dubai': 'Dubai International',\n",
        "    'zurich': 'Zurich Airport'\n",
        "}\n",
        "\n",
        "print(\"Please upload your 17 Excel files:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "airport_emotion_counts = {}\n",
        "emotion_summary_by_category = {'Smart': {}, 'Sustainable': {}, 'Hybrid': {}}\n",
        "comments_by_category = {'Smart': [], 'Sustainable': [], 'Hybrid': []}\n",
        "all_comments_by_airport = {}\n",
        "\n",
        "\n",
        "for file_name in uploaded.keys():\n",
        "\n",
        "    matched_airport = None\n",
        "    file_name_lower = file_name.lower().replace('_', '').replace(' ', '')\n",
        "\n",
        "    for keyword, airport_name in filename_to_airport.items():\n",
        "        if keyword in file_name_lower:\n",
        "            matched_airport = airport_name\n",
        "            break\n",
        "\n",
        "    if matched_airport:\n",
        "\n",
        "        airport_category = None\n",
        "        for category, airports in airport_categories.items():\n",
        "            if matched_airport in airports:\n",
        "                airport_category = category\n",
        "                break\n",
        "\n",
        "        if airport_category:\n",
        "            print(f\"Processing {file_name} -> Airport: {matched_airport} (Category: {airport_category})\")\n",
        "\n",
        "\n",
        "            df = pd.read_excel(io.BytesIO(uploaded[file_name]))\n",
        "\n",
        "            comments = df['Text - Model: Comments'].dropna().tolist()\n",
        "            all_comments_by_airport[matched_airport] = comments\n",
        "            comments_by_category[airport_category].extend(comments)\n",
        "        else:\n",
        "            print(f\"Warning: Airport {matched_airport} not found in any category. Skipping.\")\n",
        "    else:\n",
        "        print(f\"Warning: Could not match {file_name} to any airport. Skipping.\")\n",
        "\n",
        "display(HTML(\"<h3>Emotion Counts for Each Airport:</h3>\"))\n",
        "for airport, emotions in airport_emotion_counts.items():\n",
        "    airport_category = next(cat for cat, airports in airport_categories.items() if airport in airports)\n",
        "    display(HTML(f\"<h4>Airport: {airport} (Category: {airport_category})</h4>\"))\n",
        "    df_airport = pd.DataFrame(list(emotions.items()), columns=['Emotion', 'Count'])\n",
        "    display(df_airport)\n",
        "\n",
        "display(HTML(\"<h3>Summary of Emotions by Airport Category (Smart, Sustainable, Hybrid) in Counts:</h3>\"))\n",
        "summary_df = pd.DataFrame.from_dict(emotion_summary_by_category, orient='index').fillna(0).astype(int)\n",
        "display(summary_df)\n",
        "\n",
        "\n",
        "display(HTML(\"<h3>Summary of Emotions by Airport Category (Smart, Sustainable, Hybrid) in Percentages:</h3>\"))\n",
        "total_emotions = summary_df.sum(axis=1)\n",
        "percentage_df = summary_df.div(total_emotions, axis=0) * 100\n",
        "percentage_df = percentage_df.round()\n",
        "percentage_df = percentage_df.astype(str) + '%'\n",
        "display(percentage_df)\n",
        "\n",
        "\n",
        "display(HTML(\"<h3>Word Clouds for Each Airport:</h3>\"))\n",
        "for airport, comments in all_comments_by_airport.items():\n",
        "    if comments:\n",
        "        text = ' '.join(comments)\n",
        "        wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=stop_words).generate(text)\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.imshow(wordcloud, interpolation='bilinear')\n",
        "        plt.axis('off')\n",
        "        plt.title(f'Word Cloud for {airport}')\n",
        "        plt.savefig(f'wordcloud_{airport.lower().replace(\" \", \"_\")}.png')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "display(HTML(\"<h3>Word Clouds for Each Airport Category:</h3>\"))\n",
        "for category, comments in comments_by_category.items():\n",
        "    if comments:\n",
        "        text = ' '.join(comments)\n",
        "        wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=stop_words).generate(text)\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.imshow(wordcloud, interpolation='bilinear')\n",
        "        plt.axis('off')\n",
        "        plt.title(f'Word Cloud for {category} Airports')\n",
        "        plt.savefig(f'wordcloud_{category.lower()}.png')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "display(HTML(\"<h3>Clustering and Insights from Comments:</h3>\"))\n",
        "for category, comments in comments_by_category.items():\n",
        "    if len(comments) > 1:\n",
        "        display(HTML(f\"<h4>Category: {category}</h4>\"))\n",
        "\n",
        "\n",
        "        vectorizer = TfidfVectorizer(stop_words=list(stop_words), max_features=1000)\n",
        "        X = vectorizer.fit_transform(comments)\n",
        "        feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "\n",
        "        num_clusters = min(3, len(comments))\n",
        "        kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "        kmeans.fit(X)\n",
        "        labels = kmeans.labels_\n",
        "\n",
        "        perplexity = min(30, len(comments) - 1) if len(comments) > 1 else 1\n",
        "        tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity)\n",
        "        X_tsne = tsne.fit_transform(X.toarray())\n",
        "\n",
        "\n",
        "        cluster_colors = ['red', 'purple', 'green'][:num_clusters]\n",
        "        cluster_labels = [f'Cluster {i+1}' for i in range(num_clusters)]\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        for cluster_idx in range(num_clusters):\n",
        "            cluster_points = X_tsne[labels == cluster_idx]\n",
        "            plt.scatter(\n",
        "                cluster_points[:, 0],\n",
        "                cluster_points[:, 1],\n",
        "                c=cluster_colors[cluster_idx],\n",
        "                label=cluster_labels[cluster_idx],\n",
        "                s=100,\n",
        "                alpha=0.7\n",
        "            )\n",
        "\n",
        "        plt.legend(title=\"Clusters\", loc='best')\n",
        "        plt.title(f'Cluster Diagram for {category} Airports')\n",
        "        plt.xlabel('t-SNE Component 1')\n",
        "        plt.ylabel('t-SNE Component 2')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'cluster_{category.lower()}.png')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
        "        for i in range(num_clusters):\n",
        "            top_words = [feature_names[ind] for ind in order_centroids[i, :10]]\n",
        "            display(HTML(f\"<p><b>Cluster {i+1} Top Words:</b> {', '.join(top_words)}</p>\"))\n",
        "\n",
        "\n",
        "        display(HTML(\"<h5>Observations and Insights:</h5>\"))\n",
        "\n",
        "        all_text = ' '.join(comments).lower()\n",
        "        words = re.findall(r'\\b\\w+\\b', all_text)\n",
        "        filtered_words = [word for word in words if word not in stop_words and len(word) > 2]\n",
        "\n",
        "\n",
        "        word_counts = Counter(filtered_words)\n",
        "        most_common = word_counts.most_common(10)\n",
        "        display(HTML(f\"<p><b>Most Common Words:</b> {', '.join([f'{word} ({count})' for word, count in most_common])}</p>\"))\n",
        "\n",
        "\n",
        "        positive_words = sum(1 for word in filtered_words if word in ['good', 'great', 'excellent', 'amazing', 'friendly'])\n",
        "        negative_words = sum(1 for word in filtered_words if word in ['bad', 'poor', 'terrible', 'delay', 'rude'])\n",
        "        display(HTML(f\"<p><b>Positive Indicators:</b> {positive_words} mentions (e.g., good, great)</p>\"))\n",
        "        display(HTML(f\"<p><b>Negative Indicators:</b> {negative_words} mentions (e.g., bad, poor)</p>\"))\n",
        "\n",
        "\n",
        "        if category == 'Hybrid':\n",
        "            display(HTML(\"<h5>Sample Passenger Quotes:</h5>\"))\n",
        "            sample_quotes = [\n",
        "                \"Singapore Changi’s Jewel is exceptional, offering outstanding shopping and dining experiences.\",\n",
        "                \"Zurich’s terminals are clean, with efficient security processes.\",\n",
        "                \"Security queues in Dubai were excessive, taking over an hour.\",\n",
        "                \"Check-in at Singapore Changi was disorganized during peak hours.\"\n",
        "            ]\n",
        "            for quote in sample_quotes:\n",
        "                display(HTML(f\"<p>“{quote}”</p>\"))\n",
        "\n",
        "\n",
        "        display(HTML(\"<h5>User Perspective:</h5>\"))\n",
        "        perspective = f\"Passengers in {category} airports frequently mention {most_common[0][0]} and {most_common[1][0]}. \"\n",
        "        if positive_words > negative_words:\n",
        "            perspective += f\"The comments lean positive, with {positive_words} positive mentions compared to {negative_words} negative ones, suggesting overall satisfaction. \"\n",
        "        elif negative_words > positive_words:\n",
        "            perspective += f\"The comments lean negative, with {negative_words} negative mentions compared to {positive_words} positive ones, indicating areas for improvement. \"\n",
        "        else:\n",
        "            perspective += f\"The comments are balanced, with {positive_words} positive and {negative_words} negative mentions, reflecting mixed experiences. \"\n",
        "        perspective += f\"Clusters suggest distinct themes, such as {', '.join(top_words[:3])} in Cluster 1, which may reflect specific passenger concerns or experiences.\"\n",
        "        display(HTML(f\"<p>{perspective}</p>\"))\n",
        "    else:\n",
        "        display(HTML(f\"<p>No comments available for clustering in {category} category.</p>\"))"
      ],
      "metadata": {
        "id": "vlhyok_JsO_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####Table 4 and 5  Orginal one (will be replace by the above, delete\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "airport_to_category = {\n",
        "    'Incheon Airport': 'Smart',\n",
        "    'Hong Kong International': 'Smart',\n",
        "    'Amsterdam Schiphol': 'Smart',\n",
        "    'Hamad International': 'Smart',\n",
        "    'Tokyo Haneda': 'Smart',\n",
        "    'Munich Airport': 'Smart',\n",
        "    'San Francisco International': 'Smart',\n",
        "    'Denver International': 'Sustainable',\n",
        "    'Stockholm Arlanda': 'Sustainable',\n",
        "    'Indira Gandhi International': 'Sustainable',\n",
        "    'Galapagos Ecological': 'Sustainable',\n",
        "    'Oslo Airport': 'Sustainable',\n",
        "    'Boston Logan': 'Sustainable',\n",
        "    'San Diego International': 'Sustainable',\n",
        "    'Singapore Changi': 'Hybrid',\n",
        "    'Dubai International': 'Hybrid',\n",
        "    'Zurich Airport': 'Hybrid'\n",
        "}\n",
        "\n",
        "total_comments = 0\n",
        "airport_sentiment_counts = {airport: {'Positive': 0, 'Negative': 0, 'Neutral': 0} for airport in airport_to_category}\n",
        "airport_total_comments = {airport: 0 for airport in airport_to_category}\n",
        "category_emotion_counts = {\n",
        "    'Smart': {'Neutral': 0, 'Surprise': 0, 'Joy': 0, 'Disgust': 0, 'Sadness': 0, 'Fear': 0, 'Anger': 0},\n",
        "    'Sustainable': {'Neutral': 0, 'Surprise': 0, 'Joy': 0, 'Disgust': 0, 'Sadness': 0, 'Fear': 0, 'Anger': 0},\n",
        "    'Hybrid': {'Neutral': 0, 'Surprise': 0, 'Joy': 0, 'Disgust': 0, 'Sadness': 0, 'Fear': 0, 'Anger': 0}\n",
        "}\n",
        "\n",
        "print(\"Please upload 17 Excel files:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "file_to_airport = {}\n",
        "airports_list = list(airport_to_category.keys())\n",
        "\n",
        "for file_name in uploaded.keys():\n",
        "    print(f\"\\nFile: {file_name}\")\n",
        "    matched = False\n",
        "    for airport in airports_list:\n",
        "        if airport.lower() in file_name.lower():\n",
        "            file_to_airport[file_name] = airport\n",
        "            print(f\"Automatically mapped {file_name} to {airport}\")\n",
        "            matched = True\n",
        "            break\n",
        "    if not matched:\n",
        "        print(f\"No matching airport found for {file_name}. Please check the filename.\")\n",
        "\n",
        "for file_name, airport in file_to_airport.items():\n",
        "    category = airport_to_category[airport]\n",
        "    df = pd.read_excel(io.BytesIO(uploaded[file_name]))\n",
        "\n",
        "    comments = df['Text - Model: Comments'].dropna()\n",
        "    total_comments += len(comments)\n",
        "    airport_total_comments[airport] += len(comments)\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        vader_sentiment = str(row.get('vader_sentiment', '')).lower()\n",
        "        emotion = str(row.get('emotion', '')).lower()\n",
        "\n",
        "        sentiment_map = {'positive': 'Positive', 'negative': 'Negative', 'neutral': 'Neutral'}\n",
        "        if vader_sentiment in sentiment_map:\n",
        "            airport_sentiment_counts[airport][sentiment_map[vader_sentiment]] += 1\n",
        "\n",
        "        emotion_map = {\n",
        "            'neutral': 'Neutral', 'surprise': 'Surprise', 'joy': 'Joy',\n",
        "            'disgust': 'Disgust', 'sadness': 'Sadness', 'fear': 'Fear', 'anger': 'Anger'\n",
        "        }\n",
        "        if emotion in emotion_map:\n",
        "            category_emotion_counts[category][emotion_map[emotion]] += 1\n",
        "\n",
        "table_6_data = [\n",
        "    {'Category': 'Smart', 'Rank': 1, 'Airport Name': 'Incheon Airport'},\n",
        "    {'Category': 'Smart', 'Rank': 2, 'Airport Name': 'Hong Kong International'},\n",
        "    {'Category': 'Smart', 'Rank': 3, 'Airport Name': 'Amsterdam Schiphol'},\n",
        "    {'Category': 'Smart', 'Rank': 4, 'Airport Name': 'Hamad International'},\n",
        "    {'Category': 'Smart', 'Rank': 5, 'Airport Name': 'Tokyo Haneda'},\n",
        "    {'Category': 'Smart', 'Rank': 6, 'Airport Name': 'Munich Airport'},\n",
        "    {'Category': 'Smart', 'Rank': 7, 'Airport Name': 'San Francisco International'},\n",
        "    {'Category': 'Sustainable', 'Rank': 1, 'Airport Name': 'Denver International'},\n",
        "    {'Category': 'Sustainable', 'Rank': 2, 'Airport Name': 'Stockholm Arlanda'},\n",
        "    {'Category': 'Sustainable', 'Rank': 3, 'Airport Name': 'Indira Gandhi International'},\n",
        "    {'Category': 'Sustainable', 'Rank': 4, 'Airport Name': 'Galapagos Ecological'},\n",
        "    {'Category': 'Sustainable', 'Rank': 5, 'Airport Name': 'Oslo Airport'},\n",
        "    {'Category': 'Sustainable', 'Rank': 6, 'Airport Name': 'Boston Logan'},\n",
        "    {'Category': 'Sustainable', 'Rank': 7, 'Airport Name': 'San Diego International'},\n",
        "    {'Category': 'Hybrid', 'Rank': 1, 'Airport Name': 'Singapore Changi'},\n",
        "    {'Category': 'Hybrid', 'Rank': 2, 'Airport Name': 'Dubai International'},\n",
        "    {'Category': 'Hybrid', 'Rank': 3, 'Airport Name': 'Zurich Airport'}\n",
        "]\n",
        "\n",
        "for row in table_6_data:\n",
        "    airport = row['Airport Name']\n",
        "    total = airport_total_comments.get(airport, 0)\n",
        "    sentiments = airport_sentiment_counts.get(airport, {'Positive': 0, 'Negative': 0, 'Neutral': 0})\n",
        "\n",
        "    row['Positive (%)'] = round((sentiments['Positive'] / total * 100) if total > 0 else 0)\n",
        "    row['Negative (%)'] = round((sentiments['Negative'] / total * 100) if total > 0 else 0)\n",
        "    row['Neutral (%)'] = round((sentiments['Neutral'] / total * 100) if total > 0 else 0)\n",
        "    row['Total Comments'] = total\n",
        "\n",
        "table_6_df = pd.DataFrame(table_6_data)\n",
        "\n",
        "table_7_data = [\n",
        "    {'Category': 'Smart'},\n",
        "    {'Category': 'Sustainable'},\n",
        "    {'Category': 'Hybrid'}\n",
        "]\n",
        "\n",
        "for row in table_7_data:\n",
        "    category = row['Category']\n",
        "    total = sum(category_emotion_counts[category].values())\n",
        "    for emotion in ['Neutral', 'Surprise', 'Joy', 'Disgust', 'Sadness', 'Fear', 'Anger']:\n",
        "        count = category_emotion_counts[category][emotion]\n",
        "        percentage = round((count / total * 100) if total > 0 else 0)\n",
        "        row[emotion] = f\"{count} ({percentage}%)\"\n",
        "\n",
        "table_7_df = pd.DataFrame(table_7_data)\n",
        "\n",
        "table_6_df.to_excel('Updated_Table_6_Sentiment_Distribution.xlsx', index=False)\n",
        "table_7_df.to_excel('Updated_Table_7_Emotion_Summary.xlsx', index=False)\n",
        "\n",
        "files.download('Updated_Table_6_Sentiment_Distribution.xlsx')\n",
        "files.download('Updated_Table_7_Emotion_Summary.xlsx')\n",
        "\n",
        "print(f\"\\nTotal comments across all 17 Excel files: {total_comments}\")\n",
        "print(\"Updated Table 6 and Table 7 have been saved and downloaded as Excel files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cLYC12DkyyBn",
        "outputId": "13a3487f-9c2c-402b-9f71-e5fbd5374317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload 17 Excel files:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-756ba83a-d13a-4047-bca3-782154dafa7e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-756ba83a-d13a-4047-bca3-782154dafa7e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving updated_updated_updated_Amsterdam Schiphol Airport, Netherlands (1) (1) (1).xlsx to updated_updated_updated_Amsterdam Schiphol Airport, Netherlands (1) (1) (1).xlsx\n",
            "Saving updated_updated_updated_Boston Logan International Airport, USA (1) (1) (1).xlsx to updated_updated_updated_Boston Logan International Airport, USA (1) (1) (1).xlsx\n",
            "Saving updated_updated_updated_Denver International Airport, United States (1) (1) (1).xlsx to updated_updated_updated_Denver International Airport, United States (1) (1) (1).xlsx\n",
            "Saving updated_updated_updated_Dubai International Airport (1) (1) (1).xlsx to updated_updated_updated_Dubai International Airport (1) (1) (1).xlsx\n",
            "Saving updated_updated_updated_Galapagos Ecological Airport, Galapagos Islands (1) (1) (1).xlsx to updated_updated_updated_Galapagos Ecological Airport, Galapagos Islands (1) (1) (1).xlsx\n",
            "Saving updated_updated_updated_Hamad International Airport, Qatar (1) (1) (1).xlsx to updated_updated_updated_Hamad International Airport, Qatar (1) (1) (1).xlsx\n",
            "Saving updated_updated_updated_Hong Kong International Airport (2) (1) (1).xlsx to updated_updated_updated_Hong Kong International Airport (2) (1) (1).xlsx\n",
            "Saving updated_updated_updated_Incheon Airport, South Korea (1) (1) (1).xlsx to updated_updated_updated_Incheon Airport, South Korea (1) (1) (1).xlsx\n",
            "Saving updated_updated_updated_Indira Gandhi International Airport, India (1) (1) (1).xlsx to updated_updated_updated_Indira Gandhi International Airport, India (1) (1) (1).xlsx\n",
            "Saving updated_updated_updated_Munich Airport, Germany (1) (1) (1).xlsx to updated_updated_updated_Munich Airport, Germany (1) (1) (1).xlsx\n",
            "Saving updated_updated_updated_Oslo Airport, Norway (1) (1).xlsx to updated_updated_updated_Oslo Airport, Norway (1) (1) (1).xlsx\n",
            "Saving updated_updated_updated_San Diego International Airport, USA (1) (1).xlsx to updated_updated_updated_San Diego International Airport, USA (1) (1) (1).xlsx\n",
            "Saving updated_updated_updated_San Francisco International Airport, USA (1) (1).xlsx to updated_updated_updated_San Francisco International Airport, USA (1) (1) (1).xlsx\n",
            "Saving updated_updated_updated_Singapore Changi airport (1) (1).xlsx to updated_updated_updated_Singapore Changi airport (1) (1) (1).xlsx\n",
            "Saving updated_updated_updated_Stockholm Arlanda Airport, Sweden (1) (1).xlsx to updated_updated_updated_Stockholm Arlanda Airport, Sweden (1) (1) (1).xlsx\n",
            "Saving updated_updated_updated_Tokyo Haneda Airport, Japan (1) (1).xlsx to updated_updated_updated_Tokyo Haneda Airport, Japan (1) (1) (1).xlsx\n",
            "Saving updated_updated_updated_Zurich Airport (1) (1).xlsx to updated_updated_updated_Zurich Airport (1) (1) (1).xlsx\n",
            "\n",
            "File: updated_updated_updated_Amsterdam Schiphol Airport, Netherlands (1) (1) (1).xlsx\n",
            "Automatically mapped updated_updated_updated_Amsterdam Schiphol Airport, Netherlands (1) (1) (1).xlsx to Amsterdam Schiphol\n",
            "\n",
            "File: updated_updated_updated_Boston Logan International Airport, USA (1) (1) (1).xlsx\n",
            "Automatically mapped updated_updated_updated_Boston Logan International Airport, USA (1) (1) (1).xlsx to Boston Logan\n",
            "\n",
            "File: updated_updated_updated_Denver International Airport, United States (1) (1) (1).xlsx\n",
            "Automatically mapped updated_updated_updated_Denver International Airport, United States (1) (1) (1).xlsx to Denver International\n",
            "\n",
            "File: updated_updated_updated_Dubai International Airport (1) (1) (1).xlsx\n",
            "Automatically mapped updated_updated_updated_Dubai International Airport (1) (1) (1).xlsx to Dubai International\n",
            "\n",
            "File: updated_updated_updated_Galapagos Ecological Airport, Galapagos Islands (1) (1) (1).xlsx\n",
            "Automatically mapped updated_updated_updated_Galapagos Ecological Airport, Galapagos Islands (1) (1) (1).xlsx to Galapagos Ecological\n",
            "\n",
            "File: updated_updated_updated_Hamad International Airport, Qatar (1) (1) (1).xlsx\n",
            "Automatically mapped updated_updated_updated_Hamad International Airport, Qatar (1) (1) (1).xlsx to Hamad International\n",
            "\n",
            "File: updated_updated_updated_Hong Kong International Airport (2) (1) (1).xlsx\n",
            "Automatically mapped updated_updated_updated_Hong Kong International Airport (2) (1) (1).xlsx to Hong Kong International\n",
            "\n",
            "File: updated_updated_updated_Incheon Airport, South Korea (1) (1) (1).xlsx\n",
            "Automatically mapped updated_updated_updated_Incheon Airport, South Korea (1) (1) (1).xlsx to Incheon Airport\n",
            "\n",
            "File: updated_updated_updated_Indira Gandhi International Airport, India (1) (1) (1).xlsx\n",
            "Automatically mapped updated_updated_updated_Indira Gandhi International Airport, India (1) (1) (1).xlsx to Indira Gandhi International\n",
            "\n",
            "File: updated_updated_updated_Munich Airport, Germany (1) (1) (1).xlsx\n",
            "Automatically mapped updated_updated_updated_Munich Airport, Germany (1) (1) (1).xlsx to Munich Airport\n",
            "\n",
            "File: updated_updated_updated_Oslo Airport, Norway (1) (1) (1).xlsx\n",
            "Automatically mapped updated_updated_updated_Oslo Airport, Norway (1) (1) (1).xlsx to Oslo Airport\n",
            "\n",
            "File: updated_updated_updated_San Diego International Airport, USA (1) (1) (1).xlsx\n",
            "Automatically mapped updated_updated_updated_San Diego International Airport, USA (1) (1) (1).xlsx to San Diego International\n",
            "\n",
            "File: updated_updated_updated_San Francisco International Airport, USA (1) (1) (1).xlsx\n",
            "Automatically mapped updated_updated_updated_San Francisco International Airport, USA (1) (1) (1).xlsx to San Francisco International\n",
            "\n",
            "File: updated_updated_updated_Singapore Changi airport (1) (1) (1).xlsx\n",
            "Automatically mapped updated_updated_updated_Singapore Changi airport (1) (1) (1).xlsx to Singapore Changi\n",
            "\n",
            "File: updated_updated_updated_Stockholm Arlanda Airport, Sweden (1) (1) (1).xlsx\n",
            "Automatically mapped updated_updated_updated_Stockholm Arlanda Airport, Sweden (1) (1) (1).xlsx to Stockholm Arlanda\n",
            "\n",
            "File: updated_updated_updated_Tokyo Haneda Airport, Japan (1) (1) (1).xlsx\n",
            "Automatically mapped updated_updated_updated_Tokyo Haneda Airport, Japan (1) (1) (1).xlsx to Tokyo Haneda\n",
            "\n",
            "File: updated_updated_updated_Zurich Airport (1) (1) (1).xlsx\n",
            "Automatically mapped updated_updated_updated_Zurich Airport (1) (1) (1).xlsx to Zurich Airport\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b3540e54-9ab8-4642-8ea3-1c1e8d904f20\", \"Updated_Table_6_Sentiment_Distribution.xlsx\", 5686)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c37c7372-9bb4-4fd6-9ef1-d992313ee8f0\", \"Updated_Table_7_Emotion_Summary.xlsx\", 5184)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total comments across all 17 Excel files: 1587\n",
            "Updated Table 6 and Table 7 have been saved and downloaded as Excel files.\n"
          ]
        }
      ]
    }
  ]
}